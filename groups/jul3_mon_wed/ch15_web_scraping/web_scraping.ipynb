{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping\n",
    "\n",
    "## Definition\n",
    "\n",
    "Web scraping is the process of extracting data from websites. It is also known as web harvesting or web data extraction. Basically, it is a technique to convert unstructured data on the web (HTML format) into structured data (database or spreadsheet).\n",
    "\n",
    "## Why Web Scraping?\n",
    "\n",
    "Web scraping is useful when you need to collect a large amount of data from websites. You can then use the scraped data for various purposes:\n",
    "\n",
    "*   Price monitoring\n",
    "*   Market research\n",
    "*   Financial data aggregation\n",
    "*   Job listings\n",
    "*   News and content aggregation\n",
    "\n",
    "## What can be scraped?\n",
    "\n",
    "Almost all websites can be scraped. However, there are some websites that are built using technologies that make it difficult to scrape data from them. For example, websites that heavily rely on JavaScript to load content. In this case, you will need to use a headless browser to scrape the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HTML basics\n",
    "\n",
    "To scrape we need to know how to read HTML. HTML stands for HyperText Markup Language. It is the standard markup language for creating web pages. HTML describes the structure of a web page and consists of a series of elements. These elements tell the browser how to display the content.\n",
    "\n",
    "HTML is not a programming language. It is a markup language that defines the structure of your content. HTML consists of a series of elements, which you use to enclose, or wrap, different parts of the content to make it appear a certain way, or act a certain way.\n",
    "\n",
    "### Docs\n",
    "\n",
    "Getting started with HTML: [https://developer.mozilla.org/en-US/docs/Learn/HTML/Introduction_to_HTML/Getting_started](https://developer.mozilla.org/en-US/docs/Learn/HTML/Introduction_to_HTML/Getting_started)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anatomy of an HTML element\n",
    "\n",
    "![Element](https://developer.mozilla.org/en-US/docs/Learn/HTML/Introduction_to_HTML/Getting_started/grumpy-cat-small.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Markdown takes html as well\n",
    "\n",
    "Here we have an img tag\n",
    "\n",
    "<img\n",
    "  src=\"https://raw.githubusercontent.com/mdn/beginner-html-site/gh-pages/images/firefox-icon.png\"\n",
    "  alt=\"Firefox icon\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ELEMENT Attributes\n",
    "\n",
    "All HTML elements can have attributes\n",
    "\n",
    "Attributes provide additional information about an element\n",
    "\n",
    "![Element](https://developer.mozilla.org/en-US/docs/Learn/HTML/Introduction_to_HTML/Getting_started/grumpy-cat-attribute-small.png)\n",
    "\n",
    "WE will use attributes in elements to scrape data more precisely."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rental and real estate data\n",
    "\n",
    "We will use ss.com as a good example of scraping data. We will scrape rental and real estate data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.ss.com/lv/real-estate/flats/riga/centre/sell/'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"https://www.ss.com/lv/real-estate/flats/riga/centre/sell/\"\n",
    "# print (url)\n",
    "url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can check in developer tools what kind of data are there from Chrome, Safari, Firefox, etc\n",
    "\n",
    "# we see that this page uses a lot of tables\n",
    "\n",
    "# MDN docs on tables: https://developer.mozilla.org/en-US/docs/Web/HTML/Element/table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.3\n"
     ]
    }
   ],
   "source": [
    "# if we have tabular data on web page we can use pandas to read it\n",
    "\n",
    "# pandas docs on read_html https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_html.html\n",
    "\n",
    "# pandas is a huge data analysis library, we will use it for reading tables\n",
    "\n",
    "import pandas as pd # standard alias\n",
    "# version check\n",
    "print(pd.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "# pandas can read html tables and return a list of dataframes\n",
    "dfs = pd.read_html(url) # this reads ALL table elements from the page\n",
    "# how many\n",
    "print(len(dfs))\n",
    "# we need 5th table, so what index?\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sludinājumi \\tdatums</td>\n",
       "      <td>Sludinājumi \\tdatums</td>\n",
       "      <td>Sludinājumi \\tdatums</td>\n",
       "      <td>Iela</td>\n",
       "      <td>Ist.</td>\n",
       "      <td>m2</td>\n",
       "      <td>Stāvs</td>\n",
       "      <td>Sērija</td>\n",
       "      <td>Cena, m2</td>\n",
       "      <td>Cena</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Plašs dzīvoklis ar lielisku plānojumu tuvu cen...</td>\n",
       "      <td>Ieroču 1</td>\n",
       "      <td>4</td>\n",
       "      <td>108</td>\n",
       "      <td>1/5</td>\n",
       "      <td>Staļina</td>\n",
       "      <td>1,065 €</td>\n",
       "      <td>115,000 €</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pārdodam gaišu, siltu dzīvokli. 2 slēgtas guļa...</td>\n",
       "      <td>Ganību d. 25</td>\n",
       "      <td>3</td>\n",
       "      <td>73</td>\n",
       "      <td>3/3</td>\n",
       "      <td>P. kara</td>\n",
       "      <td>986 €</td>\n",
       "      <td>72,000 €</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Īpašnieks pārdod 4-istabu dzīvokli , kas sastā...</td>\n",
       "      <td>Sermuliņu 14</td>\n",
       "      <td>4</td>\n",
       "      <td>85</td>\n",
       "      <td>1/4</td>\n",
       "      <td>Jaun.</td>\n",
       "      <td>2,871 €</td>\n",
       "      <td>244,000 €</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Investīciju projekts 7. stāva izbūvei daudzdzī...</td>\n",
       "      <td>Lāčplēša 54</td>\n",
       "      <td>Citi</td>\n",
       "      <td>643</td>\n",
       "      <td>7/7</td>\n",
       "      <td>P. kara</td>\n",
       "      <td>138 €</td>\n",
       "      <td>89,000 €</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      0                     1  \\\n",
       "0  Sludinājumi \\tdatums  Sludinājumi \\tdatums   \n",
       "1                   NaN                   NaN   \n",
       "2                   NaN                   NaN   \n",
       "3                   NaN                   NaN   \n",
       "4                   NaN                   NaN   \n",
       "\n",
       "                                                   2             3     4    5  \\\n",
       "0                               Sludinājumi \\tdatums          Iela  Ist.   m2   \n",
       "1  Plašs dzīvoklis ar lielisku plānojumu tuvu cen...      Ieroču 1     4  108   \n",
       "2  Pārdodam gaišu, siltu dzīvokli. 2 slēgtas guļa...  Ganību d. 25     3   73   \n",
       "3  Īpašnieks pārdod 4-istabu dzīvokli , kas sastā...  Sermuliņu 14     4   85   \n",
       "4  Investīciju projekts 7. stāva izbūvei daudzdzī...   Lāčplēša 54  Citi  643   \n",
       "\n",
       "       6        7         8          9  \n",
       "0  Stāvs   Sērija  Cena, m2       Cena  \n",
       "1    1/5  Staļina   1,065 €  115,000 €  \n",
       "2    3/3  P. kara     986 €   72,000 €  \n",
       "3    1/4    Jaun.   2,871 €  244,000 €  \n",
       "4    7/7  P. kara     138 €   89,000 €  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = dfs[4] # we get a dataframe from 5th table\n",
    "df.head() # first 5 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i can save it now to excel or csv\n",
    "# df.to_excel(\"flats.xlsx\") # needs pip install openpyxl first\n",
    "df.to_csv(\"flats.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we would like to scrape all pages of flats\n",
    "\n",
    "# we need to find the last page number\n",
    "\n",
    "# we can use requests and beautifulsoup for that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "# beautifulsoup is a library for parsing html\n",
    "# install it with pip install beautifulsoup4\n",
    "# docs: https://www.crummy.com/software/BeautifulSoup/bs4/doc/\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we have url already lets get the page\n",
    "page = requests.get(url)\n",
    "# check if we got the page\n",
    "page.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<!DOCTYPE html>\\r\\n<HTML><HEAD>\\r\\n<title>SS.COM Dzīvokļi - Rīga - Centrs, Cenas, Pārdod - Sludinājumi</'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we got text!\n",
    "page.text[:100]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<title>SS.COM Dzīvokļi - Rīga - Centrs, Cenas, Pārdod - Sludinājumi</title>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if we did not have parser we could use find or index etc\n",
    "# it is a big string after all\n",
    "# much better it is to parse it with beautifulsoup\n",
    "# then we can access elements by tag name, class, id etc\n",
    "soup = BeautifulSoup(page.text, 'lxml') # there are other parsers too\n",
    "# lxml is a fast parser\n",
    "# title\n",
    "soup.title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we could find all anchor tags\n",
    "all_anchors = soup.find_all(\"a\") \n",
    "# mdn for anchor tag: https://developer.mozilla.org/en-US/docs/Web/HTML/Element/a\n",
    "# how many\n",
    "len(all_anchors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<a class=\"navi\" href=\"/lv/real-estate/flats/riga/centre/sell/page29.html\" name=\"nav_id\" rel=\"prev\"><img border=\"0\" height=\"5\" src=\"https://i.ss.com/img/s_left.png\" style=\"padding-bottom:2px;\" width=\"9\"/> Iepriekšējie</a>\n"
     ]
    }
   ],
   "source": [
    "# we just need a specific anchor with rel attribute and prev value\n",
    "# we can use css selectors\n",
    "# https://developer.mozilla.org/en-US/docs/Web/CSS/CSS_Selectors\n",
    "\n",
    "# or we can use soup.find\n",
    "# https://www.crummy.com/software/BeautifulSoup/bs4/doc/#find\n",
    "\n",
    "prev_anchor = soup.find(\"a\", attrs={\"rel\": \"prev\"})\n",
    "# we get the first anchor with rel=prev\n",
    "# print (prev_anchor)\n",
    "print(prev_anchor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/lv/real-estate/flats/riga/centre/sell/page29.html'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's get href attribute for this anchor\n",
    "prev_anchor[\"href\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'29'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we need to extract the page number from this href\n",
    "# we could use splits or regex\n",
    "# split approach\n",
    "last_num_str = prev_anchor[\"href\"].split(\"page\")[-1].split(\".\")[0]\n",
    "last_num_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert to integer\n",
    "last_num = int(last_num_str)\n",
    "last_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'29'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# regex approach\n",
    "import re\n",
    "# regex101.com for practice\n",
    "# regex docs: https://docs.python.org/3/library/re.html\n",
    "# so we are looking for any number of digits after page\n",
    "# we need to escape the dot\n",
    "# we need to escape the slash\n",
    "\n",
    "regex = r\"page(\\d+)\\.html\" # notice we use r for raw strings\n",
    "# because regex uses a lot of backslashes that we do not want to escape again\n",
    "my_group = re.search(regex, prev_anchor[\"href\"])\n",
    "my_group[1] # first group is everything 2nd is first match\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert to integer\n",
    "last_num = int(my_group[1])\n",
    "last_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.ss.com/lv/real-estate/flats/riga/centre/sell/',\n",
       " 'https://www.ss.com/lv/real-estate/flats/riga/centre/sell/page2.html',\n",
       " 'https://www.ss.com/lv/real-estate/flats/riga/centre/sell/page3.html',\n",
       " 'https://www.ss.com/lv/real-estate/flats/riga/centre/sell/page4.html',\n",
       " 'https://www.ss.com/lv/real-estate/flats/riga/centre/sell/page5.html',\n",
       " 'https://www.ss.com/lv/real-estate/flats/riga/centre/sell/page6.html',\n",
       " 'https://www.ss.com/lv/real-estate/flats/riga/centre/sell/page7.html',\n",
       " 'https://www.ss.com/lv/real-estate/flats/riga/centre/sell/page8.html',\n",
       " 'https://www.ss.com/lv/real-estate/flats/riga/centre/sell/page9.html',\n",
       " 'https://www.ss.com/lv/real-estate/flats/riga/centre/sell/page10.html',\n",
       " 'https://www.ss.com/lv/real-estate/flats/riga/centre/sell/page11.html',\n",
       " 'https://www.ss.com/lv/real-estate/flats/riga/centre/sell/page12.html',\n",
       " 'https://www.ss.com/lv/real-estate/flats/riga/centre/sell/page13.html',\n",
       " 'https://www.ss.com/lv/real-estate/flats/riga/centre/sell/page14.html',\n",
       " 'https://www.ss.com/lv/real-estate/flats/riga/centre/sell/page15.html',\n",
       " 'https://www.ss.com/lv/real-estate/flats/riga/centre/sell/page16.html',\n",
       " 'https://www.ss.com/lv/real-estate/flats/riga/centre/sell/page17.html',\n",
       " 'https://www.ss.com/lv/real-estate/flats/riga/centre/sell/page18.html',\n",
       " 'https://www.ss.com/lv/real-estate/flats/riga/centre/sell/page19.html',\n",
       " 'https://www.ss.com/lv/real-estate/flats/riga/centre/sell/page20.html',\n",
       " 'https://www.ss.com/lv/real-estate/flats/riga/centre/sell/page21.html',\n",
       " 'https://www.ss.com/lv/real-estate/flats/riga/centre/sell/page22.html',\n",
       " 'https://www.ss.com/lv/real-estate/flats/riga/centre/sell/page23.html',\n",
       " 'https://www.ss.com/lv/real-estate/flats/riga/centre/sell/page24.html',\n",
       " 'https://www.ss.com/lv/real-estate/flats/riga/centre/sell/page25.html',\n",
       " 'https://www.ss.com/lv/real-estate/flats/riga/centre/sell/page26.html',\n",
       " 'https://www.ss.com/lv/real-estate/flats/riga/centre/sell/page27.html',\n",
       " 'https://www.ss.com/lv/real-estate/flats/riga/centre/sell/page28.html',\n",
       " 'https://www.ss.com/lv/real-estate/flats/riga/centre/sell/page29.html']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's make a function that given a url and last page will return a list of urls\n",
    "\n",
    "def get_all_urls(url, last_page):\n",
    "    \"\"\"Returns a list of urls from 1 to last_page\"\"\"\n",
    "    # we need to get the base url\n",
    "    # base_url = url.rsplit(\"/\", 2)[0] + \"/\"\n",
    "    # print (base_url)\n",
    "    # we need to get the page number\n",
    "    # we need to get the extension\n",
    "    # we need to combine them\n",
    "    # we need to return a list of urls\n",
    "    # we need to loop from 1 to last_page\n",
    "    # we need to append to the list\n",
    "    # we need to return the list\n",
    "    # we need to return a list of urls\n",
    "    urls = [url] # we start with original\n",
    "    for page_num in range(2, last_page + 1): # we do not need first page\n",
    "        urls.append(url + f\"page{page_num}.html\")\n",
    "    return urls\n",
    "\n",
    "# test it with our url\n",
    "urls = get_all_urls(url, last_num)\n",
    "urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading https://www.ss.com/lv/real-estate/flats/riga/centre/sell/\n",
      "Reading https://www.ss.com/lv/real-estate/flats/riga/centre/sell/page2.html\n",
      "Reading https://www.ss.com/lv/real-estate/flats/riga/centre/sell/page3.html\n",
      "Reading https://www.ss.com/lv/real-estate/flats/riga/centre/sell/page4.html\n",
      "Reading https://www.ss.com/lv/real-estate/flats/riga/centre/sell/page5.html\n",
      "Reading https://www.ss.com/lv/real-estate/flats/riga/centre/sell/page6.html\n",
      "Reading https://www.ss.com/lv/real-estate/flats/riga/centre/sell/page7.html\n",
      "Reading https://www.ss.com/lv/real-estate/flats/riga/centre/sell/page8.html\n",
      "Reading https://www.ss.com/lv/real-estate/flats/riga/centre/sell/page9.html\n",
      "Reading https://www.ss.com/lv/real-estate/flats/riga/centre/sell/page10.html\n",
      "Reading https://www.ss.com/lv/real-estate/flats/riga/centre/sell/page11.html\n",
      "Reading https://www.ss.com/lv/real-estate/flats/riga/centre/sell/page12.html\n",
      "Reading https://www.ss.com/lv/real-estate/flats/riga/centre/sell/page13.html\n",
      "Reading https://www.ss.com/lv/real-estate/flats/riga/centre/sell/page14.html\n",
      "Reading https://www.ss.com/lv/real-estate/flats/riga/centre/sell/page15.html\n",
      "Reading https://www.ss.com/lv/real-estate/flats/riga/centre/sell/page16.html\n",
      "Reading https://www.ss.com/lv/real-estate/flats/riga/centre/sell/page17.html\n",
      "Reading https://www.ss.com/lv/real-estate/flats/riga/centre/sell/page18.html\n",
      "Reading https://www.ss.com/lv/real-estate/flats/riga/centre/sell/page19.html\n",
      "Reading https://www.ss.com/lv/real-estate/flats/riga/centre/sell/page20.html\n",
      "Reading https://www.ss.com/lv/real-estate/flats/riga/centre/sell/page21.html\n",
      "Reading https://www.ss.com/lv/real-estate/flats/riga/centre/sell/page22.html\n",
      "Reading https://www.ss.com/lv/real-estate/flats/riga/centre/sell/page23.html\n",
      "Reading https://www.ss.com/lv/real-estate/flats/riga/centre/sell/page24.html\n",
      "Reading https://www.ss.com/lv/real-estate/flats/riga/centre/sell/page25.html\n",
      "Reading https://www.ss.com/lv/real-estate/flats/riga/centre/sell/page26.html\n",
      "Reading https://www.ss.com/lv/real-estate/flats/riga/centre/sell/page27.html\n",
      "Reading https://www.ss.com/lv/real-estate/flats/riga/centre/sell/page28.html\n",
      "Reading https://www.ss.com/lv/real-estate/flats/riga/centre/sell/page29.html\n",
      "Got data from 29\n"
     ]
    }
   ],
   "source": [
    "# we can now iterate over urls\n",
    "# only good practice is to sleep between requests\n",
    "# 0.3 or 0.5 seconds is enough\n",
    "# it is bad practice to overload the server with requests and get banned\n",
    "\n",
    "# we can use time module for that\n",
    "import time\n",
    "\n",
    "dfs = [] # we will store all dataframes here\n",
    "for url in urls:\n",
    "    print (\"Reading\", url)\n",
    "    # we need to get the page\n",
    "    df = pd.read_html(url)[4] # we get the 5th table, this is differnt on different types of ads\n",
    "    dfs.append(df)\n",
    "    # we need to sleep\n",
    "    time.sleep(0.3) # sleep for 0.5 seconds\n",
    "# print how many we got\n",
    "print(\"Got data from\", len(dfs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sludinājumi \\tdatums</td>\n",
       "      <td>Sludinājumi \\tdatums</td>\n",
       "      <td>Sludinājumi \\tdatums</td>\n",
       "      <td>Iela</td>\n",
       "      <td>Ist.</td>\n",
       "      <td>m2</td>\n",
       "      <td>Stāvs</td>\n",
       "      <td>Sērija</td>\n",
       "      <td>Cena, m2</td>\n",
       "      <td>Cena</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pārdod gaišu un plašu 3 istabu istabu dzīvokli...</td>\n",
       "      <td>Skolas 20</td>\n",
       "      <td>3</td>\n",
       "      <td>96</td>\n",
       "      <td>5/6</td>\n",
       "      <td>Renov.</td>\n",
       "      <td>3,000 €</td>\n",
       "      <td>288,000 €</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No īpašnieka tiek pārdots plašs dzīvoklis Rīga...</td>\n",
       "      <td>Tomsona 2</td>\n",
       "      <td>4</td>\n",
       "      <td>122</td>\n",
       "      <td>3/6</td>\n",
       "      <td>P. kara</td>\n",
       "      <td>1,627 €</td>\n",
       "      <td>198,500 €</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      0                     1  \\\n",
       "0  Sludinājumi \\tdatums  Sludinājumi \\tdatums   \n",
       "1                   NaN                   NaN   \n",
       "2                   NaN                   NaN   \n",
       "\n",
       "                                                   2          3     4    5  \\\n",
       "0                               Sludinājumi \\tdatums       Iela  Ist.   m2   \n",
       "1  Pārdod gaišu un plašu 3 istabu istabu dzīvokli...  Skolas 20     3   96   \n",
       "2  No īpašnieka tiek pārdots plašs dzīvoklis Rīga...  Tomsona 2     4  122   \n",
       "\n",
       "       6        7         8          9  \n",
       "0  Stāvs   Sērija  Cena, m2       Cena  \n",
       "1    5/6   Renov.   3,000 €  288,000 €  \n",
       "2    3/6  P. kara   1,627 €  198,500 €  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's check last dataframe\n",
    "dfs[-1].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(871, 10)\n"
     ]
    }
   ],
   "source": [
    "# we can combine all dataframes into one\n",
    "df = pd.concat(dfs)\n",
    "# print shape\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to csv\n",
    "# add timestamp to filename\n",
    "from datetime import datetime\n",
    "now = datetime.now()\n",
    "timestamp = now.strftime(\"%Y%m%d_%H%M%S\")\n",
    "file_name = f\"flats_{timestamp}.csv\"\n",
    "df.to_csv(file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Things to do with BeautifulSoup\n",
    "\n",
    "We could have used BeautifulSoup to parse the HTML and extract the data we need. \n",
    "If data is not in a table, we would use BeautifulSoup to extract the data we need.\n",
    "\n",
    "One of the things missing is anchor to full ad. We can get it from the link."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I will show you how you could find link to all ads on the page \n",
    "\n",
    "# we will find all tr elements that have tr_ as start of id\n",
    "\n",
    "tr_ads = soup.find_all(\"tr\", attrs={\"id\": re.compile(\"^tr_\\d+\")}) # \\d+ means one or more digits\n",
    "len(tr_ads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tiek pārdots iedvesmojošs 4 istabu dzīvoklis ar vienreizēju plānTērbatas 2041204/6P. kara2,125 €255,000  €'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we could extract now all text from our tr_ads\n",
    "# first ad text would be \n",
    "tr_ads[0].text # minus no separator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'255,000  €'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_ad = tr_ads[0]\n",
    "# we can find all td elements and their text\n",
    "tds = first_ad.find_all(\"td\")\n",
    "tds[-1].text # last td is the price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " '',\n",
       " 'Tiek pārdots iedvesmojošs 4 istabu dzīvoklis ar vienreizēju plān',\n",
       " 'Tērbatas 20',\n",
       " '4',\n",
       " '120',\n",
       " '4/6',\n",
       " 'P. kara',\n",
       " '2,125 €',\n",
       " '255,000  €']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# so list of all texts from first ad\n",
    "first_ad_texts = [td.text for td in tds]\n",
    "first_ad_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/msg/lv/real-estate/flats/riga/centre/dcehm.html'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finally let's extract href from anchor which is in 2nd td\n",
    "# we can use find\n",
    "second_td = tds[1]\n",
    "second_td.find(\"a\")[\"href\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.ss.com/lv/real-estate/flats/riga/centre/sell/\n",
      "/msg/lv/real-estate/flats/riga/centre/dcehm.html\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'https://www.ss.com/msg/lv/real-estate/flats/riga/centre/dcehm.html'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's create a url for this ad\n",
    "url = \"https://www.ss.com/lv/real-estate/flats/riga/centre/sell/\"\n",
    "base_url = \"https://www.ss.com/\"\n",
    "suffix = second_td.find(\"a\")[\"href\"]\n",
    "print(url)\n",
    "print(suffix)\n",
    "first_ad_url = base_url.rstrip(\"/\") + suffix\n",
    "# print (first_ad_url)\n",
    "first_ad_url"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_virtual_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
